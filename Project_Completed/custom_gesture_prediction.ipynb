{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d30092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.ClassificationModule import Classifier\n",
    "import numpy as np\n",
    "import math\n",
    "from tkinter import *\n",
    "from random import randint\n",
    "import threading\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "from threading import Event, Thread\n",
    "\n",
    "\n",
    "\n",
    "timer = None\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "classifier = Classifier(\"model/keras_model.h5\", \"model/labels.txt\")\n",
    " \n",
    "offset = 20\n",
    "imgSize = 300\n",
    " \n",
    "labels = [\"A\", \"B\", \"C\"]\n",
    "sched = BackgroundScheduler()\n",
    "text = ''\n",
    "\n",
    "def predict(*args):\n",
    "    \n",
    "    global pred, timer\n",
    "    pred = True\n",
    "    time.sleep(0.05)\n",
    "    pred = False\n",
    "    timer = threading.Timer(2, predict)\n",
    "    timer.start()    \n",
    "\n",
    "predict()    \n",
    "            \n",
    "while True:\n",
    "    \n",
    "#     global hands, imgOutput, out, img, aspectRatio, imgCrop, imgWhite\n",
    "    success, img = cap.read()\n",
    "    imgOutput = img.copy()\n",
    "    hands, img = detector.findHands(img)\n",
    "    out = img.copy()\n",
    "    \n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "        imgCropShape = imgCrop.shape\n",
    "\n",
    "        aspectRatio = h / w\n",
    "\n",
    "#         cv2.rectangle(imgOutput, (x - offset, y - offset-50),(x - offset+90, y - offset-50+50), (255, 0, 255), cv2.FILLED)\n",
    "#         cv2.putText(imgOutput, labels[index], (x, y -26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.rectangle(imgOutput, (x-offset, y-offset),(x + w+offset, y + h+offset), (0, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(out, text, (50,100), cv2.FONT_HERSHEY_COMPLEX, 1.7, (0, 0, 255), 3)\n",
    "    \n",
    "    if pred and hands:\n",
    "        alpha = 0.01\n",
    "        mask = imgOutput.astype(bool)\n",
    "        out[mask] = cv2.addWeighted(img, alpha, imgOutput, 1 - alpha, 0)[mask]\n",
    "        cv2.imshow(\"ImageO\", out)\n",
    "\n",
    "        if aspectRatio > 1:\n",
    "            k = imgSize / h\n",
    "            wCal = math.ceil(k * w)\n",
    "            imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "            imgResizeShape = imgResize.shape\n",
    "            wGap = math.ceil((imgSize - wCal) / 2)\n",
    "            imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "            prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "\n",
    "        else:\n",
    "            k = imgSize / w\n",
    "            hCal = math.ceil(k * h)\n",
    "            imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "            imgResizeShape = imgResize.shape\n",
    "            hGap = math.ceil((imgSize - hCal) / 2)\n",
    "            imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "            prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "\n",
    "\n",
    "        def update(text):\n",
    "            if labels[index] in 'ADEFGHIJKLMNOPQRSTUVWXYZ':\n",
    "                text = text+labels[index]\n",
    "            elif labels[index] == 'B' and text:\n",
    "                text = text[:-1]\n",
    "            elif labels[index] == 'C':\n",
    "                text = text+' '\n",
    "\n",
    "            return text\n",
    "\n",
    "        text = update(text)    \n",
    "                     \n",
    "    else:    \n",
    "        cv2.imshow(\"ImageO\", out)\n",
    "        \n",
    "    k = cv2.waitKey(5)\n",
    "    if k == ord('q'):\n",
    "        timer.cancel()\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bca044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every 10 seconds\n",
      "Every 10 seconds\n",
      "Every 10 seconds\n",
      "Every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "# note that there are many other schedulers available\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "sched = BackgroundScheduler()\n",
    "\n",
    "def some_job():\n",
    "    print('Every 10 seconds')\n",
    "\n",
    "# seconds can be replaced with minutes, hours, or days\n",
    "sched.add_job(some_job, 'interval', seconds=10)\n",
    "sched.start()\n",
    "\n",
    "...\n",
    "\n",
    "sched.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "226c5cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every 10 seconds\n",
      "Every 10 seconds\n",
      "Every 10 seconds\n",
      "Every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from threading import Event, Thread\n",
    "\n",
    "class RepeatedTimer:\n",
    "\n",
    "    \"\"\"Repeat `function` every `interval` seconds.\"\"\"\n",
    "\n",
    "    def __init__(self, interval, function, *args, **kwargs):\n",
    "        self.interval = interval\n",
    "        self.function = function\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.start = time.time()\n",
    "        self.event = Event()\n",
    "        self.thread = Thread(target=self._target)\n",
    "        self.thread.start()\n",
    "\n",
    "    def _target(self):\n",
    "        while not self.event.wait(self._time):\n",
    "            self.function(*self.args, **self.kwargs)\n",
    "\n",
    "    @property\n",
    "    def _time(self):\n",
    "        return self.interval - ((time.time() - self.start) % self.interval)\n",
    "\n",
    "    def stop(self):\n",
    "        self.event.set()\n",
    "        self.thread.join()\n",
    "\n",
    "\n",
    "# start timer\n",
    "timer = RepeatedTimer(10, print, 'Hello world')\n",
    "\n",
    "# stop timer\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14eabdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.ClassificationModule import Classifier\n",
    "import numpy as np\n",
    "import math\n",
    "from tkinter import *\n",
    "from random import randint\n",
    "import threading\n",
    "from pynput.keyboard import Key, Controller\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "classifier = Classifier(\"model/keras_model.h5\", \"model/labels.txt\")\n",
    "\n",
    "keyboard = Controller()\n",
    "\n",
    "offset = 20\n",
    "imgSize = 300\n",
    " \n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'DELETE', 'SPACE', 'CLEAR']\n",
    "text = ''\n",
    "\n",
    "t = None\n",
    "\n",
    "def press():\n",
    "    global t\n",
    "    keyboard.press('s')\n",
    "    keyboard.release('s') \n",
    "    t = threading.Timer(2, press)\n",
    "    t.start()\n",
    "    \n",
    "press()\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgOutput = img.copy()\n",
    "    hands, img = detector.findHands(img)\n",
    "    out = img.copy()\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "        imgCropShape = imgCrop.shape\n",
    "\n",
    "        aspectRatio = h / w\n",
    "\n",
    "#         cv2.rectangle(imgOutput, (x - offset, y - offset-50),(x - offset+90, y - offset-50+50), (255, 0, 255), cv2.FILLED)\n",
    "#         cv2.putText(imgOutput, labels[index], (x, y -26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.rectangle(imgOutput, (x-offset, y-offset),(x + w+offset, y + h+offset), (0, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(out, text, (50,100), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                \n",
    "    key = cv2.waitKey(5)\n",
    "     \n",
    "    if key == ord('s') and hands:\n",
    "        \n",
    "        alpha = 0.01\n",
    "        mask = imgOutput.astype(bool)\n",
    "        out[mask] = cv2.addWeighted(img, alpha, imgOutput, 1 - alpha, 0)[mask]\n",
    "        cv2.imshow(\"ImageO\", out)\n",
    "        \n",
    "        \n",
    "        if aspectRatio > 1:\n",
    "            k = imgSize / h\n",
    "            wCal = math.ceil(k * w)\n",
    "            imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "            imgResizeShape = imgResize.shape\n",
    "            wGap = math.ceil((imgSize - wCal) / 2)\n",
    "            imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "            cv2.imshow('imagewhite', imgWhite)\n",
    "            prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "\n",
    "        else:\n",
    "            k = imgSize / w\n",
    "            hCal = math.ceil(k * h)\n",
    "            imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "            imgResizeShape = imgResize.shape\n",
    "            hGap = math.ceil((imgSize - hCal) / 2)\n",
    "            imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "            cv2.imshow('imagewhite', imgWhite)\n",
    "            prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "        \n",
    "        \n",
    "        def update(text):\n",
    "            if labels[index] in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n",
    "                text = text+labels[index]\n",
    "            elif labels[index] == 'DELETE' and text:\n",
    "                text = text[:-1]\n",
    "            elif labels[index] == 'SPACE':\n",
    "                text = text+' '\n",
    "            elif labels[index] == 'CLEAR':\n",
    "                text = ''\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "            return text\n",
    "\n",
    "        text = update(text)\n",
    "        \n",
    "    else:    \n",
    "        cv2.imshow(\"ImageO\", out)\n",
    "        \n",
    "    k = cv2.waitKey(5)\n",
    "    if k == ord('q'):\n",
    "        t.cancel()\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16780bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ae685",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = HandDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Webcam Live Feed\")\n",
    "run = st.checkbox('Run')\n",
    "FRAME_WINDOW = st.image([])\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while run:\n",
    "    _, frame = camera.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    FRAME_WINDOW.image(frame)\n",
    "else:\n",
    "    st.write('Stopped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc97a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10672288",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,29):\n",
    "        valid_samples = random.sample(os.listdir(f'Data/train/{i}'), 15)\n",
    "        for j in valid_samples:\n",
    "            shutil.move(f'Data/train/{i}/{j}', f'Data/valid/{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "973f000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,29):\n",
    "        test_samples = random.sample(os.listdir(f'Data/train/{i}'), 5)\n",
    "        for j in test_samples:\n",
    "            shutil.move(f'Data/train/{i}/{j}', f'Data/test/{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b849f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import cv2\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aca0de25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/riyaz/Desktop/Hand_Recognition/data/Project_Completed'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8a8653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = cv2.imread('Data/train/19/Image_1665134195.6849296.jpg')\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e3276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Data/train'\n",
    "valid_path = 'Data/valid'\n",
    "test_path = 'Data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "963d0a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2320 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "                                  directory=train_path, target_size=(224,224), batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e804b6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 435 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "                                  directory=valid_path, target_size=(224,224), batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbdab945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 145 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "                                  directory=test_path, target_size=(224,224), batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4c67749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobile = tf.keras.applications.MobileNet(input_shape=(300,300,3),include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a701e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = tf.keras.applications.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd59f00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 112, 112, 32)     128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)     288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 32)     128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 64)     256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)      0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 7, 7, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1, 1, 1024)       0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_preds (Conv2D)         (None, 1, 1, 1000)        1025000   \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1000)              0         \n",
      "                                                                 \n",
      " predictions (Activation)    (None, 1000)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,253,864\n",
      "Trainable params: 4,231,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4eed908",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mobile.layers[-5].output\n",
    "y = tf.reshape(x, shape=(-1, 1024))\n",
    "output = Dense(units=29, activation='softmax')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d33ff352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=mobile.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d6f1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d951e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 112, 112, 32)     128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)     288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 32)     128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 64)     256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)      0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 7, 7, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1, 1, 1024)       0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " tf.reshape (TFOpLambda)     (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 29)                29725     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,258,589\n",
      "Trainable params: 1,892,381\n",
      "Non-trainable params: 1,366,208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf1c807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ab347a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "145/145 - 52s - loss: 0.6154 - accuracy: 0.8728 - val_loss: 0.3354 - val_accuracy: 0.9218 - 52s/epoch - 359ms/step\n",
      "Epoch 2/25\n",
      "145/145 - 57s - loss: 0.0389 - accuracy: 0.9996 - val_loss: 0.0260 - val_accuracy: 0.9977 - 57s/epoch - 394ms/step\n",
      "Epoch 3/25\n",
      "145/145 - 55s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000 - 55s/epoch - 381ms/step\n",
      "Epoch 4/25\n",
      "145/145 - 55s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000 - 55s/epoch - 380ms/step\n",
      "Epoch 5/25\n",
      "145/145 - 66s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000 - 66s/epoch - 456ms/step\n",
      "Epoch 6/25\n",
      "145/145 - 74s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - 74s/epoch - 513ms/step\n",
      "Epoch 7/25\n",
      "145/145 - 71s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000 - 71s/epoch - 486ms/step\n",
      "Epoch 8/25\n",
      "145/145 - 71s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000 - 71s/epoch - 486ms/step\n",
      "Epoch 9/25\n",
      "145/145 - 72s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - 72s/epoch - 497ms/step\n",
      "Epoch 10/25\n",
      "145/145 - 63s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - 63s/epoch - 437ms/step\n",
      "Epoch 11/25\n",
      "145/145 - 61s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - 61s/epoch - 423ms/step\n",
      "Epoch 12/25\n",
      "145/145 - 61s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.5924e-04 - val_accuracy: 1.0000 - 61s/epoch - 424ms/step\n",
      "Epoch 13/25\n",
      "145/145 - 64s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.2844e-04 - val_accuracy: 1.0000 - 64s/epoch - 440ms/step\n",
      "Epoch 14/25\n",
      "145/145 - 69s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.8126e-04 - val_accuracy: 1.0000 - 69s/epoch - 478ms/step\n",
      "Epoch 15/25\n",
      "145/145 - 68s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.9648e-04 - val_accuracy: 1.0000 - 68s/epoch - 467ms/step\n",
      "Epoch 16/25\n",
      "145/145 - 72s - loss: 9.1022e-04 - accuracy: 1.0000 - val_loss: 5.2860e-04 - val_accuracy: 1.0000 - 72s/epoch - 494ms/step\n",
      "Epoch 17/25\n",
      "145/145 - 71s - loss: 7.7899e-04 - accuracy: 1.0000 - val_loss: 4.9083e-04 - val_accuracy: 1.0000 - 71s/epoch - 489ms/step\n",
      "Epoch 18/25\n",
      "145/145 - 69s - loss: 6.5583e-04 - accuracy: 1.0000 - val_loss: 4.2349e-04 - val_accuracy: 1.0000 - 69s/epoch - 477ms/step\n",
      "Epoch 19/25\n",
      "145/145 - 78s - loss: 5.8820e-04 - accuracy: 1.0000 - val_loss: 3.6198e-04 - val_accuracy: 1.0000 - 78s/epoch - 537ms/step\n",
      "Epoch 20/25\n",
      "145/145 - 80s - loss: 5.0378e-04 - accuracy: 1.0000 - val_loss: 3.2842e-04 - val_accuracy: 1.0000 - 80s/epoch - 551ms/step\n",
      "Epoch 21/25\n",
      "145/145 - 77s - loss: 4.9276e-04 - accuracy: 1.0000 - val_loss: 2.9911e-04 - val_accuracy: 1.0000 - 77s/epoch - 528ms/step\n",
      "Epoch 22/25\n",
      "145/145 - 73s - loss: 4.5758e-04 - accuracy: 1.0000 - val_loss: 2.4949e-04 - val_accuracy: 1.0000 - 73s/epoch - 504ms/step\n",
      "Epoch 23/25\n",
      "145/145 - 73s - loss: 3.7822e-04 - accuracy: 1.0000 - val_loss: 2.3097e-04 - val_accuracy: 1.0000 - 73s/epoch - 501ms/step\n",
      "Epoch 24/25\n",
      "145/145 - 74s - loss: 3.3960e-04 - accuracy: 1.0000 - val_loss: 2.0571e-04 - val_accuracy: 1.0000 - 74s/epoch - 510ms/step\n",
      "Epoch 25/25\n",
      "145/145 - 73s - loss: 2.9962e-04 - accuracy: 1.0000 - val_loss: 1.7712e-04 - val_accuracy: 1.0000 - 73s/epoch - 502ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ccc5cd3f0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=25, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f5d157c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('transferlearned_gesture.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b213eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '10': 2,\n",
       " '11': 3,\n",
       " '12': 4,\n",
       " '13': 5,\n",
       " '14': 6,\n",
       " '15': 7,\n",
       " '16': 8,\n",
       " '17': 9,\n",
       " '18': 10,\n",
       " '19': 11,\n",
       " '2': 12,\n",
       " '20': 13,\n",
       " '21': 14,\n",
       " '22': 15,\n",
       " '23': 16,\n",
       " '24': 17,\n",
       " '25': 18,\n",
       " '26': 19,\n",
       " '27': 20,\n",
       " '28': 21,\n",
       " '3': 22,\n",
       " '4': 23,\n",
       " '5': 24,\n",
       " '6': 25,\n",
       " '7': 26,\n",
       " '8': 27,\n",
       " '9': 28}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "714c8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'DELETE', 'SPACE', 'CLEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35b3a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_label = []\n",
    "for key in test_batches.class_indices.keys():\n",
    "    random_label.append(labels[int(key)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51ba5207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'B',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'C',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'DELETE',\n",
       " 'SPACE',\n",
       " 'CLEAR',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33a48e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb598178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,\n",
       "        3,  3,  3,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  6,  6,  6,  6,\n",
       "        6,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9, 10,\n",
       "       10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13,\n",
       "       13, 13, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 20, 20,\n",
       "       20, 20, 20, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 23, 23, 23, 23,\n",
       "       23, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 27,\n",
       "       27, 27, 27, 27, 28, 28, 28, 28, 28], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b29577c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model/transferlearned_gesture.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aca081be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x=test_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8e570dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred = pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb264aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'DELETE', 'SPACE', 'CLEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fb57aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(cm, display_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c9eb33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fc7da13cc40>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "# disp.plot(cmap = plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d511358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "165bcd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 29)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d1c83905",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for i in range(145):\n",
    "    ls.append(np.argmax(pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c9a15d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.ClassificationModule import Classifier\n",
    "import numpy as np\n",
    "import math\n",
    "from tkinter import *\n",
    "from random import randint\n",
    "import threading\n",
    "from pynput.keyboard import Key, Controller\n",
    "import tensorflow as tf\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "\n",
    "model = tf.keras.models.load_model('model/transferlearned_gesture.h5')\n",
    "# model = Classifier(\"model/keras_model.h5\", \"model/labels.txt\")\n",
    "\n",
    "keyboard = Controller()\n",
    "\n",
    "offset = 20\n",
    "imgSize = 224\n",
    " \n",
    "# labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'DELETE', 'SPACE', 'CLEAR']    \n",
    "randLabels = ['A','B','K','L','M','N','O','P','Q','R','S','T','C','U','V','W','X','Y','Z','DELETE','SPACE','CLEAR','D','E','F','G','H','I','J']\n",
    "text = ''\n",
    "\n",
    "t = None\n",
    "\n",
    "def press():\n",
    "    global t\n",
    "    keyboard.press('s')\n",
    "    keyboard.release('s') \n",
    "    t = threading.Timer(2, press)\n",
    "    t.start()\n",
    "    \n",
    "press()\n",
    "\n",
    "success = True\n",
    "\n",
    "while success:\n",
    "    try:\n",
    "        success, img = cap.read()\n",
    "        imgOutput = img.copy()\n",
    "        hands, img = detector.findHands(img)\n",
    "        out = img.copy()\n",
    "        if hands:\n",
    "            hand = hands[0]\n",
    "            x, y, w, h = hand['bbox']\n",
    "\n",
    "            imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "            imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "            imgCropShape = imgCrop.shape\n",
    "\n",
    "            aspectRatio = h / w\n",
    "\n",
    "    #         cv2.rectangle(imgOutput, (x - offset, y - offset-50),(x - offset+90, y - offset-50+50), (255, 0, 255), cv2.FILLED)\n",
    "    #         cv2.putText(imgOutput, labels[index], (x, y -26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)\n",
    "\n",
    "            cv2.rectangle(imgOutput, (x-offset, y-offset),(x + w+offset, y + h+offset), (0, 0, 255), cv2.FILLED)\n",
    "            cv2.putText(out, text, (50,100), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        key = cv2.waitKey(5)\n",
    "\n",
    "        if key == ord('s') and hands:\n",
    "\n",
    "            alpha = 0.01\n",
    "            mask = imgOutput.astype(bool)\n",
    "            out[mask] = cv2.addWeighted(img, alpha, imgOutput, 1 - alpha, 0)[mask]\n",
    "            cv2.imshow(\"ImageO\", out)\n",
    "\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "\n",
    "                norm=imgWhite/255.0\n",
    "                reshaped=np.reshape(norm,(1,224,224,3))\n",
    "                reshaped = np.vstack([reshaped])\n",
    "\n",
    "#                 pred, index = model.getPrediction(imgWhite, draw=False)\n",
    "\n",
    "                pred = model.predict(reshaped)\n",
    "                index = np.argmax(pred)\n",
    "\n",
    "\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "\n",
    "                norm=imgWhite/255.0\n",
    "                reshaped=np.reshape(norm,(1,224,224,3))\n",
    "                reshaped = np.vstack([reshaped])\n",
    "\n",
    "#                 pred, index = model.getPrediction(imgWhite, draw=False)\n",
    "\n",
    "                pred = model.predict(reshaped)\n",
    "                index = np.argmax(pred)\n",
    "\n",
    "\n",
    "            def update(text):\n",
    "                if randLabels[index] in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n",
    "                    text = text+randLabels[index]\n",
    "                elif randLabels[index] == 'DELETE' and text:\n",
    "                    text = text[:-1]\n",
    "                elif randLabels[index] == 'SPACE':\n",
    "                    text = text+' '\n",
    "                elif randLabels[index] == 'CLEAR':\n",
    "                    text = ''\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                return text\n",
    "\n",
    "            text = update(text)\n",
    "\n",
    "        else:    \n",
    "            cv2.imshow(\"ImageO\", out)\n",
    "\n",
    "        k = cv2.waitKey(5)\n",
    "        if k == ord('q'):\n",
    "            break\n",
    "    except:\n",
    "        print('an error occured')\n",
    "\n",
    "t.cancel()        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df5afa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "70d737ae54b238b53e6aaf55d50ae2e689114a4e24da510ce0185f0e055da354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
